{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add batch effects\n",
    "\n",
    "Say we are interested in identifying genes that differentiate between disease vs normal states.  However our dataset includes samples from different tissues or time points and there are variations in gene expression that are due to these other conditions and do not have to do with disease state.  These non-relevant variations in the data are called *batch effects*.  \n",
    "\n",
    "We want to model these batch effects.  To do this we will:\n",
    "1. Partition our simulated data into n batches\n",
    "2. For each partition we will randomly shift the expression data.  We randomly generate a binary vector of length=number of genes (*offset vector*).  This vector will serve as the direction that we will shift to.  Then we also have a random scalar that will tell us how big of a step to take in our random direction (*stretch factor*).  We shift our partitioned data by: batch effect partition = partitioned data + stretch factor * offset vector\n",
    "3. Repeat this for each partition\n",
    "4. Append all batch effect partitions together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import umap\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_file = \"config_exp_2.txt\"\n",
    "\n",
    "d = {}\n",
    "float_params = [\"learning_rate\", \"kappa\", \"epsilon_std\"]\n",
    "str_params = [\"analysis_name\", \"NN_architecture\"]\n",
    "lst_params = [\"num_batches\"]\n",
    "with open(config_file) as f:\n",
    "    for line in f:\n",
    "        (name, val) = line.split()\n",
    "        if name in float_params:\n",
    "            d[name] = float(val)\n",
    "        elif name in str_params:\n",
    "            d[name] = str(val)\n",
    "        elif name in lst_params:\n",
    "            d[name] = ast.literal_eval(val)\n",
    "        else:\n",
    "            d[name] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "analysis_name = d[\"analysis_name\"]\n",
    "NN_architecture = d[\"NN_architecture\"]\n",
    "num_PCs = d[\"num_PCs\"]\n",
    "num_batches = d[\"num_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists: /home/alexandra/Documents/Repos/Batch_effects_simulation/data/batch_simulated/experiment_2\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "\n",
    "new_dir = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"batch_simulated\")\n",
    "\n",
    "analysis_dir = os.path.join(new_dir, analysis_name)\n",
    "\n",
    "if os.path.exists(analysis_dir):\n",
    "    print('directory already exists: {}'.format(analysis_dir))\n",
    "else:\n",
    "    print('creating new directory: {}'.format(analysis_dir))\n",
    "os.makedirs(analysis_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arguments\n",
    "simulated_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"simulated_data.txt.xz\")\n",
    "\n",
    "umap_model_file = umap_model_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"models\",  \n",
    "    NN_architecture,\n",
    "    \"umap_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in UMAP model\n",
    "infile = open(umap_model_file, 'rb')\n",
    "umap_model = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5340</th>\n",
       "      <th>339</th>\n",
       "      <th>244</th>\n",
       "      <th>1567</th>\n",
       "      <th>1827</th>\n",
       "      <th>4981</th>\n",
       "      <th>2310</th>\n",
       "      <th>3929</th>\n",
       "      <th>1498</th>\n",
       "      <th>3226</th>\n",
       "      <th>...</th>\n",
       "      <th>2787</th>\n",
       "      <th>2526</th>\n",
       "      <th>3299</th>\n",
       "      <th>3097</th>\n",
       "      <th>5330</th>\n",
       "      <th>2854</th>\n",
       "      <th>494</th>\n",
       "      <th>5089</th>\n",
       "      <th>3662</th>\n",
       "      <th>1920</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535602</td>\n",
       "      <td>0.503128</td>\n",
       "      <td>0.285015</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.338972</td>\n",
       "      <td>0.563961</td>\n",
       "      <td>0.324290</td>\n",
       "      <td>0.469941</td>\n",
       "      <td>0.185681</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544562</td>\n",
       "      <td>0.256521</td>\n",
       "      <td>0.326031</td>\n",
       "      <td>0.611043</td>\n",
       "      <td>0.412167</td>\n",
       "      <td>0.438068</td>\n",
       "      <td>0.280573</td>\n",
       "      <td>0.609067</td>\n",
       "      <td>0.402821</td>\n",
       "      <td>0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.602998</td>\n",
       "      <td>0.314449</td>\n",
       "      <td>0.170274</td>\n",
       "      <td>0.150126</td>\n",
       "      <td>0.393875</td>\n",
       "      <td>0.425789</td>\n",
       "      <td>0.359611</td>\n",
       "      <td>0.367097</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558114</td>\n",
       "      <td>0.284270</td>\n",
       "      <td>0.290870</td>\n",
       "      <td>0.574704</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.427374</td>\n",
       "      <td>0.250592</td>\n",
       "      <td>0.675274</td>\n",
       "      <td>0.470036</td>\n",
       "      <td>0.133792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517498</td>\n",
       "      <td>0.419739</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.131460</td>\n",
       "      <td>0.324510</td>\n",
       "      <td>0.413850</td>\n",
       "      <td>0.320531</td>\n",
       "      <td>0.416758</td>\n",
       "      <td>0.152202</td>\n",
       "      <td>0.088437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792330</td>\n",
       "      <td>0.273688</td>\n",
       "      <td>0.418673</td>\n",
       "      <td>0.734889</td>\n",
       "      <td>0.254353</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.249746</td>\n",
       "      <td>0.694683</td>\n",
       "      <td>0.476522</td>\n",
       "      <td>0.128183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397841</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0.249936</td>\n",
       "      <td>0.297673</td>\n",
       "      <td>0.476715</td>\n",
       "      <td>0.381297</td>\n",
       "      <td>0.468330</td>\n",
       "      <td>0.215541</td>\n",
       "      <td>0.132116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590046</td>\n",
       "      <td>0.380182</td>\n",
       "      <td>0.329754</td>\n",
       "      <td>0.520238</td>\n",
       "      <td>0.422373</td>\n",
       "      <td>0.406375</td>\n",
       "      <td>0.207356</td>\n",
       "      <td>0.601750</td>\n",
       "      <td>0.407103</td>\n",
       "      <td>0.174844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.535997</td>\n",
       "      <td>0.465947</td>\n",
       "      <td>0.277286</td>\n",
       "      <td>0.222062</td>\n",
       "      <td>0.385123</td>\n",
       "      <td>0.421842</td>\n",
       "      <td>0.330086</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.128083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557488</td>\n",
       "      <td>0.298452</td>\n",
       "      <td>0.395627</td>\n",
       "      <td>0.590282</td>\n",
       "      <td>0.290962</td>\n",
       "      <td>0.399933</td>\n",
       "      <td>0.272622</td>\n",
       "      <td>0.597588</td>\n",
       "      <td>0.440435</td>\n",
       "      <td>0.206779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.493290</td>\n",
       "      <td>0.396501</td>\n",
       "      <td>0.249366</td>\n",
       "      <td>0.159639</td>\n",
       "      <td>0.375957</td>\n",
       "      <td>0.402583</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.381382</td>\n",
       "      <td>0.261653</td>\n",
       "      <td>0.081041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688526</td>\n",
       "      <td>0.281114</td>\n",
       "      <td>0.452581</td>\n",
       "      <td>0.688948</td>\n",
       "      <td>0.270457</td>\n",
       "      <td>0.273857</td>\n",
       "      <td>0.142955</td>\n",
       "      <td>0.579213</td>\n",
       "      <td>0.546091</td>\n",
       "      <td>0.433394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.433612</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.179525</td>\n",
       "      <td>0.336945</td>\n",
       "      <td>0.345377</td>\n",
       "      <td>0.321877</td>\n",
       "      <td>0.382335</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629592</td>\n",
       "      <td>0.270185</td>\n",
       "      <td>0.363605</td>\n",
       "      <td>0.600325</td>\n",
       "      <td>0.337987</td>\n",
       "      <td>0.378784</td>\n",
       "      <td>0.203119</td>\n",
       "      <td>0.582426</td>\n",
       "      <td>0.467594</td>\n",
       "      <td>0.176376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.451588</td>\n",
       "      <td>0.457565</td>\n",
       "      <td>0.336580</td>\n",
       "      <td>0.272774</td>\n",
       "      <td>0.264118</td>\n",
       "      <td>0.369123</td>\n",
       "      <td>0.275050</td>\n",
       "      <td>0.424156</td>\n",
       "      <td>0.250198</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390592</td>\n",
       "      <td>0.251810</td>\n",
       "      <td>0.273909</td>\n",
       "      <td>0.448068</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.366531</td>\n",
       "      <td>0.295605</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.335833</td>\n",
       "      <td>0.287866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.619654</td>\n",
       "      <td>0.442385</td>\n",
       "      <td>0.281102</td>\n",
       "      <td>0.209915</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>0.559756</td>\n",
       "      <td>0.303963</td>\n",
       "      <td>0.474562</td>\n",
       "      <td>0.233043</td>\n",
       "      <td>0.112126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427282</td>\n",
       "      <td>0.366223</td>\n",
       "      <td>0.458586</td>\n",
       "      <td>0.647082</td>\n",
       "      <td>0.318879</td>\n",
       "      <td>0.373176</td>\n",
       "      <td>0.295560</td>\n",
       "      <td>0.716585</td>\n",
       "      <td>0.483560</td>\n",
       "      <td>0.206377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.434846</td>\n",
       "      <td>0.361911</td>\n",
       "      <td>0.255196</td>\n",
       "      <td>0.199091</td>\n",
       "      <td>0.345327</td>\n",
       "      <td>0.390971</td>\n",
       "      <td>0.342980</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.176265</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.281425</td>\n",
       "      <td>0.373171</td>\n",
       "      <td>0.545738</td>\n",
       "      <td>0.388045</td>\n",
       "      <td>0.386622</td>\n",
       "      <td>0.230204</td>\n",
       "      <td>0.596523</td>\n",
       "      <td>0.427771</td>\n",
       "      <td>0.195655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5340       339       244      1567      1827      4981      2310  \\\n",
       "0  0.535602  0.503128  0.285015  0.182251  0.338972  0.563961  0.324290   \n",
       "1  0.602998  0.314449  0.170274  0.150126  0.393875  0.425789  0.359611   \n",
       "2  0.517498  0.419739  0.182155  0.131460  0.324510  0.413850  0.320531   \n",
       "3  0.397841  0.457606  0.323778  0.249936  0.297673  0.476715  0.381297   \n",
       "4  0.535997  0.465947  0.277286  0.222062  0.385123  0.421842  0.330086   \n",
       "5  0.493290  0.396501  0.249366  0.159639  0.375957  0.402583  0.275842   \n",
       "6  0.433612  0.351818  0.241003  0.179525  0.336945  0.345377  0.321877   \n",
       "7  0.451588  0.457565  0.336580  0.272774  0.264118  0.369123  0.275050   \n",
       "8  0.619654  0.442385  0.281102  0.209915  0.417300  0.559756  0.303963   \n",
       "9  0.434846  0.361911  0.255196  0.199091  0.345327  0.390971  0.342980   \n",
       "\n",
       "       3929      1498      3226    ...         2787      2526      3299  \\\n",
       "0  0.469941  0.185681  0.090720    ...     0.544562  0.256521  0.326031   \n",
       "1  0.367097  0.162651  0.060858    ...     0.558114  0.284270  0.290870   \n",
       "2  0.416758  0.152202  0.088437    ...     0.792330  0.273688  0.418673   \n",
       "3  0.468330  0.215541  0.132116    ...     0.590046  0.380182  0.329754   \n",
       "4  0.415129  0.177301  0.128083    ...     0.557488  0.298452  0.395627   \n",
       "5  0.381382  0.261653  0.081041    ...     0.688526  0.281114  0.452581   \n",
       "6  0.382335  0.167349  0.141031    ...     0.629592  0.270185  0.363605   \n",
       "7  0.424156  0.250198  0.247813    ...     0.390592  0.251810  0.273909   \n",
       "8  0.474562  0.233043  0.112126    ...     0.427282  0.366223  0.458586   \n",
       "9  0.392987  0.176265  0.135802    ...     0.615511  0.281425  0.373171   \n",
       "\n",
       "       3097      5330      2854       494      5089      3662      1920  \n",
       "0  0.611043  0.412167  0.438068  0.280573  0.609067  0.402821  0.158164  \n",
       "1  0.574704  0.281427  0.427374  0.250592  0.675274  0.470036  0.133792  \n",
       "2  0.734889  0.254353  0.468174  0.249746  0.694683  0.476522  0.128183  \n",
       "3  0.520238  0.422373  0.406375  0.207356  0.601750  0.407103  0.174844  \n",
       "4  0.590282  0.290962  0.399933  0.272622  0.597588  0.440435  0.206779  \n",
       "5  0.688948  0.270457  0.273857  0.142955  0.579213  0.546091  0.433394  \n",
       "6  0.600325  0.337987  0.378784  0.203119  0.582426  0.467594  0.176376  \n",
       "7  0.448068  0.424536  0.366531  0.295605  0.435115  0.335833  0.287866  \n",
       "8  0.647082  0.318879  0.373176  0.295560  0.716585  0.483560  0.206377  \n",
       "9  0.545738  0.388045  0.386622  0.230204  0.596523  0.427771  0.195655  \n",
       "\n",
       "[10 rows x 5000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "simulated_data = pd.read_table(\n",
    "    simulated_data_file,\n",
    "    header=0, \n",
    "    index_col=0,\n",
    "    compression='xz',\n",
    "    sep='\\t')\n",
    "\n",
    "simulated_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simulated data with 1 batches..\n",
      "Creating simulated data with 2 batches..\n",
      "Creating simulated data with 5 batches..\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add batch effects\n",
    "num_simulated_samples = simulated_data.shape[0]\n",
    "num_genes = simulated_data.shape[1]\n",
    "subset_genes_to_change = np.random.RandomState(randomState).choice([0, 1], size=(num_genes), p=[1./4, 3./4])\n",
    "    \n",
    "for i in num_batches:\n",
    "    print('Creating simulated data with {} batches..'.format(i))\n",
    "    \n",
    "    batch_file = os.path.join(\n",
    "            base_dir,\n",
    "            \"data\",\n",
    "            \"batch_simulated\",\n",
    "            analysis_name,\n",
    "            \"Batch_\"+str(i)+\".txt.xz\")\n",
    "    \n",
    "    num_samples_per_batch = int(num_simulated_samples/i)\n",
    "    \n",
    "    if i == 1:        \n",
    "        simulated_data.to_csv(batch_file, sep='\\t', compression='xz')\n",
    "        \n",
    "    else:  \n",
    "        batch_data_df = pd.DataFrame()\n",
    "        \n",
    "        simulated_data_draw = simulated_data\n",
    "        for j in range(i):\n",
    "            #print(j)\n",
    "            # Randomly select samples\n",
    "            batch_df = simulated_data_draw.sample(n=num_samples_per_batch, frac=None, replace=False)\n",
    "            batch_df.columns = batch_df.columns.astype(str)\n",
    "            \n",
    "            # Update df to remove selected samples\n",
    "            sampled_ids = list(batch_df.index)\n",
    "            simulated_data_draw = simulated_data_draw.drop(sampled_ids)\n",
    "\n",
    "            # Add batch effect\n",
    "            \n",
    "            # Option 1: Add small amount to subset of genes\n",
    "            stretch_factor = np.random.uniform(0,1.0)\n",
    "            #stretch_factor = 0.0\n",
    "            subset_genes_to_change_tile = pd.DataFrame(\n",
    "                pd.np.tile(\n",
    "                    subset_genes_to_change,\n",
    "                    (num_samples_per_batch, 1)),\n",
    "                index=batch_df.index,\n",
    "                columns=simulated_data.columns)\n",
    "\n",
    "            offset_vector = pd.DataFrame(subset_genes_to_change_tile*stretch_factor)\n",
    "            offset_vector.columns = offset_vector.columns.astype(str)\n",
    "            #print(subset_genes_to_change_tile)\n",
    "            \n",
    "            batch_df = batch_df + offset_vector\n",
    "            \n",
    "            #print(batch_df)\n",
    "            \n",
    "            # Option 2: Multiply all samples by small scale factor\n",
    "            #stretch_factor = np.random.uniform(1.0,1.5)\n",
    "            #batch_df = batch_df*stretch_factor\n",
    "\n",
    "            # if any exceed 1 then set to 1 since gene expression is normalized\n",
    "            batch_df[batch_df>=1.0] = 1.0\n",
    "\n",
    "            # Append batched together\n",
    "            batch_data_df = batch_data_df.append(batch_df)\n",
    "\n",
    "            # Select a new direction (i.e. a new subset of genes to change)\n",
    "            np.random.shuffle(subset_genes_to_change)\n",
    "        #break\n",
    "            \n",
    "        # Save\n",
    "        batch_data_df.to_csv(batch_file, sep='\\t', compression='xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot batch data using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plot generated data \n",
    "\n",
    "for i in num_batches:\n",
    "    batch_data_file = os.path.join(\n",
    "        base_dir,\n",
    "        \"data\",\n",
    "        \"batch_simulated\",\n",
    "        analysis_name,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "    \n",
    "    batch_data = pd.read_table(\n",
    "        batch_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # UMAP embedding of decoded batch data\n",
    "    batch_data_UMAPencoded = umap_model.transform(batch_data)\n",
    "    batch_data_UMAPencoded_df = pd.DataFrame(data=batch_data_UMAPencoded,\n",
    "                                             index=batch_data.index,\n",
    "                                             columns=['1','2'])\n",
    "    \n",
    "        \n",
    "    g = ggplot(aes(x='1',y='2'), data=batch_data_UMAPencoded_df) + \\\n",
    "                geom_point(alpha=0.5) + \\\n",
    "                scale_color_brewer(type='qual', palette='Set2') + \\\n",
    "                ggtitle(\"{} Batches\".format(i))\n",
    "    \n",
    "    print(g)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot batch data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plot generated data \n",
    "\n",
    "for i in num_batches:\n",
    "    batch_data_file = os.path.join(\n",
    "        base_dir,\n",
    "        \"data\",\n",
    "        \"batch_simulated\",\n",
    "        analysis_name,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "    \n",
    "    batch_data = pd.read_table(\n",
    "        batch_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # PCA projection    \n",
    "    pca = PCA(n_components=num_PCs)\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_data)\n",
    "    \n",
    "    # Encode data using PCA model    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_data.index\n",
    "                                         )\n",
    "    \n",
    "    g = sns.pairplot(batch_data_PCAencoded_df)\n",
    "    g.fig.suptitle(\"Batch {}\".format(i))\n",
    "       \n",
    "    # Select pairwise PC's to plot\n",
    "    pc1 = 0\n",
    "    pc2 = 2\n",
    "    \n",
    "    # Encode data using PCA model    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded[:,[pc1,pc2]],\n",
    "                                         index=batch_data.index,\n",
    "                                         columns=['PC {}'.format(pc1), 'PC {}'.format(pc2)])\n",
    "    \n",
    "    g = ggplot(aes(x='PC {}'.format(pc1),y='PC {}'.format(pc2)), data=batch_data_PCAencoded_df)  + \\\n",
    "                geom_point(alpha=0.5) + \\\n",
    "                scale_color_brewer(type='qual', palette='Set2') + \\\n",
    "                ggtitle(\"{} Batches\".format(i))\n",
    "    print(g)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
