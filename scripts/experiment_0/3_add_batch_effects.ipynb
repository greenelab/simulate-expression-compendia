{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add batch effects\n",
    "\n",
    "Say we are interested in identifying genes that differentiate between disease vs normal states.  However our dataset includes samples from different tissues or time points and there are variations in gene expression that are due to these other conditions and do not have to do with disease state.  These non-relevant variations in the data are called *batch effects*.  \n",
    "\n",
    "We want to model these batch effects.  To do this we will:\n",
    "1. Partition our simulated data into n batches\n",
    "2. For each partition we will randomly shift the expression data.  We randomly generate a binary vector of length=number of genes (*offset vector*).  This vector will serve as the direction that we will shift to.  Then we also have a random scalar that will tell us how big of a step to take in our random direction (*stretch factor*).  We shift our partitioned data by: batch effect partition = partitioned data + stretch factor * offset vector\n",
    "3. Repeat this for each partition\n",
    "4. Append all batch effect partitions together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import umap\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from ggplot import *\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.random import seed\n",
    "randomState = 123\n",
    "seed(randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "config_file = \"config_exp_0.txt\"\n",
    "\n",
    "d = {}\n",
    "float_params = [\"learning_rate\", \"kappa\", \"epsilon_std\"]\n",
    "str_params = [\"analysis_name\", \"NN_architecture\"]\n",
    "lst_params = [\"num_batches\"]\n",
    "with open(config_file) as f:\n",
    "    for line in f:\n",
    "        (name, val) = line.split()\n",
    "        if name in float_params:\n",
    "            d[name] = float(val)\n",
    "        elif name in str_params:\n",
    "            d[name] = str(val)\n",
    "        elif name in lst_params:\n",
    "            d[name] = ast.literal_eval(val)\n",
    "        else:\n",
    "            d[name] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "analysis_name = d[\"analysis_name\"]\n",
    "NN_architecture = d[\"NN_architecture\"]\n",
    "num_PCs = d[\"num_PCs\"]\n",
    "num_batches = d[\"num_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists: /home/alexandra/Documents/Playground/Batch_effects_simulation_local/data/batch_simulated/experiment_0\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "\n",
    "new_dir = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"batch_simulated\")\n",
    "\n",
    "analysis_dir = os.path.join(new_dir, analysis_name)\n",
    "\n",
    "if os.path.exists(analysis_dir):\n",
    "    print('directory already exists: {}'.format(analysis_dir))\n",
    "else:\n",
    "    print('creating new directory: {}'.format(analysis_dir))\n",
    "os.makedirs(analysis_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arguments\n",
    "simulated_data_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"data\",\n",
    "    \"simulated\",\n",
    "    analysis_name,\n",
    "    \"simulated_data.txt.xz\")\n",
    "\n",
    "umap_model_file = umap_model_file = os.path.join(\n",
    "    base_dir,\n",
    "    \"models\",  \n",
    "    NN_architecture,\n",
    "    \"umap_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in UMAP model\n",
    "infile = open(umap_model_file, 'rb')\n",
    "umap_model = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5340</th>\n",
       "      <th>339</th>\n",
       "      <th>244</th>\n",
       "      <th>1567</th>\n",
       "      <th>1827</th>\n",
       "      <th>4981</th>\n",
       "      <th>2310</th>\n",
       "      <th>3929</th>\n",
       "      <th>1498</th>\n",
       "      <th>3226</th>\n",
       "      <th>...</th>\n",
       "      <th>2641</th>\n",
       "      <th>4645</th>\n",
       "      <th>4585</th>\n",
       "      <th>1696</th>\n",
       "      <th>5218</th>\n",
       "      <th>249</th>\n",
       "      <th>2655</th>\n",
       "      <th>4782</th>\n",
       "      <th>1293</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535602</td>\n",
       "      <td>0.503128</td>\n",
       "      <td>0.285015</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.338972</td>\n",
       "      <td>0.563961</td>\n",
       "      <td>0.324290</td>\n",
       "      <td>0.469941</td>\n",
       "      <td>0.185681</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358896</td>\n",
       "      <td>0.654506</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.213065</td>\n",
       "      <td>0.555343</td>\n",
       "      <td>0.346773</td>\n",
       "      <td>0.231398</td>\n",
       "      <td>0.207239</td>\n",
       "      <td>0.548592</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.602998</td>\n",
       "      <td>0.314449</td>\n",
       "      <td>0.170274</td>\n",
       "      <td>0.150126</td>\n",
       "      <td>0.393875</td>\n",
       "      <td>0.425789</td>\n",
       "      <td>0.359611</td>\n",
       "      <td>0.367097</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.569583</td>\n",
       "      <td>0.461774</td>\n",
       "      <td>0.141425</td>\n",
       "      <td>0.559661</td>\n",
       "      <td>0.404262</td>\n",
       "      <td>0.193320</td>\n",
       "      <td>0.256343</td>\n",
       "      <td>0.604435</td>\n",
       "      <td>0.563223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517498</td>\n",
       "      <td>0.419739</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.131460</td>\n",
       "      <td>0.324510</td>\n",
       "      <td>0.413850</td>\n",
       "      <td>0.320531</td>\n",
       "      <td>0.416758</td>\n",
       "      <td>0.152202</td>\n",
       "      <td>0.088437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354576</td>\n",
       "      <td>0.599023</td>\n",
       "      <td>0.410843</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.510072</td>\n",
       "      <td>0.403116</td>\n",
       "      <td>0.197580</td>\n",
       "      <td>0.239914</td>\n",
       "      <td>0.713293</td>\n",
       "      <td>0.624423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397841</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0.249936</td>\n",
       "      <td>0.297673</td>\n",
       "      <td>0.476715</td>\n",
       "      <td>0.381297</td>\n",
       "      <td>0.468330</td>\n",
       "      <td>0.215541</td>\n",
       "      <td>0.132116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451938</td>\n",
       "      <td>0.411013</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>0.290338</td>\n",
       "      <td>0.430163</td>\n",
       "      <td>0.377278</td>\n",
       "      <td>0.377678</td>\n",
       "      <td>0.328690</td>\n",
       "      <td>0.521566</td>\n",
       "      <td>0.390877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.535997</td>\n",
       "      <td>0.465947</td>\n",
       "      <td>0.277286</td>\n",
       "      <td>0.222062</td>\n",
       "      <td>0.385123</td>\n",
       "      <td>0.421842</td>\n",
       "      <td>0.330086</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.128083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495980</td>\n",
       "      <td>0.525113</td>\n",
       "      <td>0.432366</td>\n",
       "      <td>0.201250</td>\n",
       "      <td>0.606396</td>\n",
       "      <td>0.380384</td>\n",
       "      <td>0.209951</td>\n",
       "      <td>0.288402</td>\n",
       "      <td>0.563646</td>\n",
       "      <td>0.583976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.493290</td>\n",
       "      <td>0.396501</td>\n",
       "      <td>0.249366</td>\n",
       "      <td>0.159639</td>\n",
       "      <td>0.375957</td>\n",
       "      <td>0.402583</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.381382</td>\n",
       "      <td>0.261653</td>\n",
       "      <td>0.081041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342845</td>\n",
       "      <td>0.670070</td>\n",
       "      <td>0.407004</td>\n",
       "      <td>0.215835</td>\n",
       "      <td>0.587762</td>\n",
       "      <td>0.397528</td>\n",
       "      <td>0.236528</td>\n",
       "      <td>0.251614</td>\n",
       "      <td>0.600678</td>\n",
       "      <td>0.718417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.433612</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.179525</td>\n",
       "      <td>0.336945</td>\n",
       "      <td>0.345377</td>\n",
       "      <td>0.321877</td>\n",
       "      <td>0.382335</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442284</td>\n",
       "      <td>0.484055</td>\n",
       "      <td>0.402640</td>\n",
       "      <td>0.323867</td>\n",
       "      <td>0.504018</td>\n",
       "      <td>0.418877</td>\n",
       "      <td>0.241006</td>\n",
       "      <td>0.274514</td>\n",
       "      <td>0.596295</td>\n",
       "      <td>0.556387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.451588</td>\n",
       "      <td>0.457565</td>\n",
       "      <td>0.336580</td>\n",
       "      <td>0.272774</td>\n",
       "      <td>0.264118</td>\n",
       "      <td>0.369123</td>\n",
       "      <td>0.275050</td>\n",
       "      <td>0.424156</td>\n",
       "      <td>0.250198</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417076</td>\n",
       "      <td>0.499973</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.261137</td>\n",
       "      <td>0.453874</td>\n",
       "      <td>0.425273</td>\n",
       "      <td>0.294926</td>\n",
       "      <td>0.293479</td>\n",
       "      <td>0.535604</td>\n",
       "      <td>0.471286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.619654</td>\n",
       "      <td>0.442385</td>\n",
       "      <td>0.281102</td>\n",
       "      <td>0.209915</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>0.559756</td>\n",
       "      <td>0.303963</td>\n",
       "      <td>0.474562</td>\n",
       "      <td>0.233043</td>\n",
       "      <td>0.112126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436053</td>\n",
       "      <td>0.675932</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>0.213318</td>\n",
       "      <td>0.691767</td>\n",
       "      <td>0.300163</td>\n",
       "      <td>0.260528</td>\n",
       "      <td>0.281530</td>\n",
       "      <td>0.509397</td>\n",
       "      <td>0.618331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.434846</td>\n",
       "      <td>0.361911</td>\n",
       "      <td>0.255196</td>\n",
       "      <td>0.199091</td>\n",
       "      <td>0.345327</td>\n",
       "      <td>0.390971</td>\n",
       "      <td>0.342980</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.176265</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465793</td>\n",
       "      <td>0.475744</td>\n",
       "      <td>0.384862</td>\n",
       "      <td>0.209843</td>\n",
       "      <td>0.521720</td>\n",
       "      <td>0.375902</td>\n",
       "      <td>0.241566</td>\n",
       "      <td>0.250671</td>\n",
       "      <td>0.527586</td>\n",
       "      <td>0.522440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5340       339       244      1567      1827      4981      2310  \\\n",
       "0  0.535602  0.503128  0.285015  0.182251  0.338972  0.563961  0.324290   \n",
       "1  0.602998  0.314449  0.170274  0.150126  0.393875  0.425789  0.359611   \n",
       "2  0.517498  0.419739  0.182155  0.131460  0.324510  0.413850  0.320531   \n",
       "3  0.397841  0.457606  0.323778  0.249936  0.297673  0.476715  0.381297   \n",
       "4  0.535997  0.465947  0.277286  0.222062  0.385123  0.421842  0.330086   \n",
       "5  0.493290  0.396501  0.249366  0.159639  0.375957  0.402583  0.275842   \n",
       "6  0.433612  0.351818  0.241003  0.179525  0.336945  0.345377  0.321877   \n",
       "7  0.451588  0.457565  0.336580  0.272774  0.264118  0.369123  0.275050   \n",
       "8  0.619654  0.442385  0.281102  0.209915  0.417300  0.559756  0.303963   \n",
       "9  0.434846  0.361911  0.255196  0.199091  0.345327  0.390971  0.342980   \n",
       "\n",
       "       3929      1498      3226    ...         2641      4645      4585  \\\n",
       "0  0.469941  0.185681  0.090720    ...     0.358896  0.654506  0.352168   \n",
       "1  0.367097  0.162651  0.060858    ...     0.411636  0.569583  0.461774   \n",
       "2  0.416758  0.152202  0.088437    ...     0.354576  0.599023  0.410843   \n",
       "3  0.468330  0.215541  0.132116    ...     0.451938  0.411013  0.378725   \n",
       "4  0.415129  0.177301  0.128083    ...     0.495980  0.525113  0.432366   \n",
       "5  0.381382  0.261653  0.081041    ...     0.342845  0.670070  0.407004   \n",
       "6  0.382335  0.167349  0.141031    ...     0.442284  0.484055  0.402640   \n",
       "7  0.424156  0.250198  0.247813    ...     0.417076  0.499973  0.297584   \n",
       "8  0.474562  0.233043  0.112126    ...     0.436053  0.675932  0.392779   \n",
       "9  0.392987  0.176265  0.135802    ...     0.465793  0.475744  0.384862   \n",
       "\n",
       "       1696      5218       249      2655      4782      1293       767  \n",
       "0  0.213065  0.555343  0.346773  0.231398  0.207239  0.548592  0.610000  \n",
       "1  0.141425  0.559661  0.404262  0.193320  0.256343  0.604435  0.563223  \n",
       "2  0.257731  0.510072  0.403116  0.197580  0.239914  0.713293  0.624423  \n",
       "3  0.290338  0.430163  0.377278  0.377678  0.328690  0.521566  0.390877  \n",
       "4  0.201250  0.606396  0.380384  0.209951  0.288402  0.563646  0.583976  \n",
       "5  0.215835  0.587762  0.397528  0.236528  0.251614  0.600678  0.718417  \n",
       "6  0.323867  0.504018  0.418877  0.241006  0.274514  0.596295  0.556387  \n",
       "7  0.261137  0.453874  0.425273  0.294926  0.293479  0.535604  0.471286  \n",
       "8  0.213318  0.691767  0.300163  0.260528  0.281530  0.509397  0.618331  \n",
       "9  0.209843  0.521720  0.375902  0.241566  0.250671  0.527586  0.522440  \n",
       "\n",
       "[10 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "simulated_data = pd.read_table(\n",
    "    simulated_data_file,\n",
    "    header=0, \n",
    "    index_col=0,\n",
    "    compression='xz',\n",
    "    sep='\\t')\n",
    "\n",
    "simulated_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simulated data with 1 batches..\n",
      "Creating simulated data with 2 batches..\n",
      "Creating simulated data with 5 batches..\n",
      "Creating simulated data with 10 batches..\n",
      "Creating simulated data with 20 batches..\n",
      "Creating simulated data with 50 batches..\n",
      "Creating simulated data with 100 batches..\n",
      "Creating simulated data with 500 batches..\n",
      "Creating simulated data with 1000 batches..\n",
      "Creating simulated data with 2000 batches..\n",
      "Creating simulated data with 3000 batches..\n"
     ]
    }
   ],
   "source": [
    "# Add batch effects\n",
    "# ADD MULTIPLE SIMULATION RUNS\n",
    "num_simulated_samples = simulated_data.shape[0]\n",
    "num_genes = simulated_data.shape[1]\n",
    "subset_genes_to_change = np.random.RandomState(randomState).choice([0, 1], size=(num_genes), p=[3./4, 1./4])\n",
    "    \n",
    "for i in num_batches:\n",
    "    print('Creating simulated data with {} batches..'.format(i))\n",
    "    \n",
    "    batch_file = os.path.join(\n",
    "            base_dir,\n",
    "            \"data\",\n",
    "            \"batch_simulated\",\n",
    "            analysis_name,\n",
    "            \"Batch_\"+str(i)+\".txt.xz\")\n",
    "    \n",
    "    num_samples_per_batch = int(num_simulated_samples/i)\n",
    "    \n",
    "    if i == 1:        \n",
    "        simulated_data.to_csv(batch_file, sep='\\t', compression='xz')\n",
    "        \n",
    "    else:  \n",
    "        batch_data_df = pd.DataFrame()\n",
    "        \n",
    "        simulated_data_draw = simulated_data\n",
    "        for j in range(i):\n",
    "            stretch_factor = np.random.uniform(1.0,1.5)\n",
    "            \n",
    "            # Randomly select samples\n",
    "            batch_df = simulated_data_draw.sample(n=num_samples_per_batch, frac=None, replace=False)\n",
    "            batch_df.columns = batch_df.columns.astype(str)\n",
    "            \n",
    "            # Update df to remove selected samples\n",
    "            sampled_ids = list(batch_df.index)\n",
    "            simulated_data_draw = simulated_data_draw.drop(sampled_ids)\n",
    "\n",
    "            # Add batch effect\n",
    "            subset_genes_to_change_tile = pd.DataFrame(\n",
    "                pd.np.tile(\n",
    "                    subset_genes_to_change,\n",
    "                    (num_samples_per_batch, 1)),\n",
    "                index=batch_df.index,\n",
    "                columns=simulated_data.columns)\n",
    "\n",
    "            offset_vector = pd.DataFrame(subset_genes_to_change_tile*stretch_factor)\n",
    "            offset_vector.columns = offset_vector.columns.astype(str)\n",
    "            batch_df = batch_df + offset_vector\n",
    "            \n",
    "            #batch_df = batch_df*stretch_factor\n",
    "\n",
    "            # if any exceed 1 then set to 1 since gene expression is normalized\n",
    "            batch_df[batch_df>=1.0] = 1.0\n",
    "\n",
    "            # Append batched together\n",
    "            batch_data_df = batch_data_df.append(batch_df)\n",
    "\n",
    "            # Select a new direction (i.e. a new subset of genes to change)\n",
    "            np.random.shuffle(subset_genes_to_change)\n",
    "        \n",
    "        # Save\n",
    "        batch_data_df.to_csv(batch_file, sep='\\t', compression='xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot batch data using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plot generated data \n",
    "\n",
    "for i in num_batches:\n",
    "    batch_data_file = os.path.join(\n",
    "        base_dir,\n",
    "        \"data\",\n",
    "        \"batch_simulated\",\n",
    "        analysis_name,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "    \n",
    "    batch_data = pd.read_table(\n",
    "        batch_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # UMAP embedding of decoded batch data\n",
    "    batch_data_UMAPencoded = umap_model.transform(batch_data)\n",
    "    batch_data_UMAPencoded_df = pd.DataFrame(data=batch_data_UMAPencoded,\n",
    "                                             index=batch_data.index,\n",
    "                                             columns=['1','2'])\n",
    "    \n",
    "        \n",
    "    g = ggplot(aes(x='1',y='2'), data=batch_data_UMAPencoded_df) + \\\n",
    "                geom_point(alpha=0.5) + \\\n",
    "                scale_color_brewer(type='qual', palette='Set2') + \\\n",
    "                ggtitle(\"{} Batches\".format(i))\n",
    "    \n",
    "    print(g)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot batch data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plot generated data \n",
    "\n",
    "for i in num_batches:\n",
    "    batch_data_file = os.path.join(\n",
    "        base_dir,\n",
    "        \"data\",\n",
    "        \"batch_simulated\",\n",
    "        analysis_name,\n",
    "        \"Batch_\"+str(i)+\".txt\")\n",
    "    \n",
    "    batch_data = pd.read_table(\n",
    "        batch_data_file,\n",
    "        header=0,\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "    \n",
    "    # PCA projection    \n",
    "    pca = PCA(n_components=num_PCs)\n",
    "    batch_data_PCAencoded = pca.fit_transform(batch_data)\n",
    "    \n",
    "    # Encode data using PCA model    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded,\n",
    "                                         index=batch_data.index\n",
    "                                         )\n",
    "    \n",
    "    g = sns.pairplot(batch_data_PCAencoded_df)\n",
    "    g.fig.suptitle(\"Batch {}\".format(i))\n",
    "       \n",
    "    # Select pairwise PC's to plot\n",
    "    pc1 = 0\n",
    "    pc2 = 2\n",
    "    \n",
    "    # Encode data using PCA model    \n",
    "    batch_data_PCAencoded_df = pd.DataFrame(batch_data_PCAencoded[:,[pc1,pc2]],\n",
    "                                         index=batch_data.index,\n",
    "                                         columns=['PC {}'.format(pc1), 'PC {}'.format(pc2)])\n",
    "    \n",
    "    g = ggplot(aes(x='PC {}'.format(pc1),y='PC {}'.format(pc2)), data=batch_data_PCAencoded_df)  + \\\n",
    "                geom_point(alpha=0.5) + \\\n",
    "                scale_color_brewer(type='qual', palette='Set2') + \\\n",
    "                ggtitle(\"{} Batches\".format(i))\n",
    "    print(g)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batch_effects]",
   "language": "python",
   "name": "conda-env-batch_effects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
